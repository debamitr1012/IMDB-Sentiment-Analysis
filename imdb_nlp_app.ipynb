{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09209b26",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis using Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76f816e",
   "metadata": {},
   "source": [
    "## IMDB Reviews NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c9b35a",
   "metadata": {},
   "source": [
    "# \n",
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49da06aa",
   "metadata": {},
   "source": [
    "# \n",
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\IMDB Dataset.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ee49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary statistics of numerical features : \\n\", df.describe())\n",
    "print(\"\\nTotal number of reviews: \",len(df))\n",
    "print(\"\\nTotal number of Sentiments: \", len(list(set(df['sentiment']))))\n",
    "df['sentiment'] = np.where(df['sentiment'] == \"positive\", 1, 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ad8cfa",
   "metadata": {},
   "source": [
    "# \n",
    "Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7af9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "df['sentiment'].value_counts().sort_index().plot(kind='bar',color = 'blue')\n",
    "plt.title('Distribution of Rating')\n",
    "plt.grid()\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "ax = plt.axes()\n",
    "ax.set_facecolor(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8614cbd",
   "metadata": {},
   "source": [
    "# \n",
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9048f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.1, random_state=0) #uncomment to use full set of data\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2e3a96",
   "metadata": {},
   "source": [
    "# \n",
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98fdaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], \\\n",
    "                                                    test_size=0.1, random_state=0)\n",
    "print('Load %d training examples and %d validation examples. \\n' %(X_train.shape[0],X_test.shape[0]))\n",
    "print('Show a review in the training set : \\n', X_train.iloc[10])\n",
    "X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4a1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(raw_text, remove_stopwords=False, stemming=False, split_text=False, \\\n",
    "             ):\n",
    "    text = BeautifulSoup(raw_text, 'html.parser').get_text()\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    words = letters_only.lower().split() \n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    if stemming==True:\n",
    "        stemmer = SnowballStemmer('english') \n",
    "        words = [stemmer.stem(w) for w in words]\n",
    "    if split_text==True:\n",
    "        return (words)\n",
    "    return( \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af264103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from bs4 import BeautifulSoup \n",
    "import logging\n",
    "from wordcloud import WordCloud\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "X_train_cleaned = []\n",
    "X_test_cleaned = []\n",
    "for d in X_train:\n",
    "    X_train_cleaned.append(cleanText(d))\n",
    "print('Show a cleaned review in the training set : \\n',  X_train_cleaned[10])   \n",
    "for d in X_test:\n",
    "    X_test_cleaned.append(cleanText(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778d2768",
   "metadata": {},
   "source": [
    "# \n",
    "CountVectorizer with Mulinomial Naive Bayes (Benchmark Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f1bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "countVect = CountVectorizer() \n",
    "X_train_countVect = countVect.fit_transform(X_train_cleaned)\n",
    "print(\"Number of features : %d \\n\" %len(countVect.get_feature_names())) #6378 \n",
    "print(\"Show some feature names : \\n\", countVect.get_feature_names()[::1000])\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_countVect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3950995",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(countVect,open('countVect_imdb.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "def modelEvaluation(predictions):\n",
    "    print (\"\\nAccuracy on validation set: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "    print(\"\\nAUC score : {:.4f}\".format(roc_auc_score(y_test, predictions)))\n",
    "    print(\"\\nClassification report : \\n\", metrics.classification_report(y_test, predictions))\n",
    "    print(\"\\nConfusion Matrix : \\n\", metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mnb.predict(countVect.transform(X_test_cleaned))\n",
    "modelEvaluation(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d3e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(mnb,open('Naive_Bayes_model_imdb.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a798a6d3",
   "metadata": {},
   "source": [
    "# \n",
    "TfidfVectorizer with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25307947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "tfidf = TfidfVectorizer(min_df=5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "print(\"Number of features : %d \\n\" %len(tfidf.get_feature_names()))\n",
    "print(\"Show some feature names : \\n\", tfidf.get_feature_names()[::1000])\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(tfidf.get_feature_names())\n",
    "sorted_coef_index = lr.coef_[0].argsort()\n",
    "print('\\nTop 10 features with smallest coefficients :\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Top 10 features with largest coefficients : \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1471b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(tfidf.transform(X_test_cleaned))\n",
    "modelEvaluation(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b171548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "estimators = [(\"tfidf\", TfidfVectorizer()), (\"lr\", LogisticRegression())]\n",
    "model = Pipeline(estimators)\n",
    "params = {\"lr__C\":[0.1, 1, 10], \n",
    "          \"tfidf__min_df\": [1, 3], \n",
    "          \"tfidf__max_features\": [1000, None], \n",
    "          \"tfidf__ngram_range\": [(1,1), (1,2)], \n",
    "          \"tfidf__stop_words\": [None, \"english\"]} \n",
    "grid = GridSearchCV(estimator=model, param_grid=params, scoring=\"accuracy\", n_jobs=-1)\n",
    "grid.fit(X_train_cleaned, y_train)\n",
    "print(\"The best paramenter set is : \\n\", grid.best_params_)\n",
    "predictions = grid.predict(X_test_cleaned)\n",
    "modelEvaluation(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb96c0de",
   "metadata": {},
   "source": [
    "# \n",
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "def parseSent(review, tokenizer, remove_stopwords=False):\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(cleanText(raw_sentence, remove_stopwords, split_text=True))\n",
    "    return sentences\n",
    "sentences = []\n",
    "for review in X_train_cleaned:\n",
    "    sentences += parseSent(review, tokenizer,remove_stopwords=False)\n",
    "print('%d parsed sentence in the training set\\n'  %len(sentences))\n",
    "print('Show a parsed sentence in the training set : \\n',  sentences[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2716faa7",
   "metadata": {},
   "source": [
    "# \n",
    "Creating Vocabulary List using Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "num_features = 300                     \n",
    "min_word_count = 10                \n",
    "num_workers = 4       \n",
    "context = 10                                                                                          \n",
    "downsampling = 1e-3 \n",
    "print(\"Training Word2Vec model ...\\n\")\n",
    "w2v = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count,\\\n",
    "                 window = context, sample = downsampling)\n",
    "w2v.init_sims(replace=True)\n",
    "w2v.save(\"w2v_300features_10minwordcounts_10context\") \n",
    "print(\"Number of words in the vocabulary list : %d \\n\" %len(w2v.wv.index2word)) \n",
    "print(\"Show first 10 words in the vocalbulary list  vocabulary list: \\n\", w2v.wv.index2word[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f58ed",
   "metadata": {},
   "source": [
    "# \n",
    "Averaging Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVec(review, model, num_features):\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    nwords = 0.\n",
    "    index2word_set = set(model.wv.index2word) \n",
    "    isZeroVec = True\n",
    "    for word in review:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "            isZeroVec = False\n",
    "    if isZeroVec == False:\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acab687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model,num_features)\n",
    "        counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcf7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned = []\n",
    "for review in X_train:\n",
    "    X_train_cleaned.append(cleanText(review, remove_stopwords=True, split_text=True))\n",
    "trainVector = getAvgFeatureVecs(X_train_cleaned, w2v, num_features)\n",
    "print(\"Training set : %d feature vectors with %d dimensions\" %trainVector.shape)\n",
    "X_test_cleaned = []\n",
    "for review in X_test:\n",
    "    X_test_cleaned.append(cleanText(review, remove_stopwords=True, split_text=True))\n",
    "testVector = getAvgFeatureVecs(X_test_cleaned, w2v, num_features)\n",
    "print(\"Validation set : %d feature vectors with %d dimensions\" %testVector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7e9e0",
   "metadata": {},
   "source": [
    "# \n",
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(trainVector, y_train)\n",
    "predictions = rf.predict(testVector)\n",
    "modelEvaluation(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc61e7eb",
   "metadata": {},
   "source": [
    "# \n",
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b000d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from collections import defaultdict\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras import backend as K\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cea761",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 40000 \n",
    "maxlen = 200 \n",
    "batch_size = 62\n",
    "nb_classes = 4\n",
    "nb_epoch = 6\n",
    "tokenizer = Tokenizer(nb_words=top_words) \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_seq = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n",
    "X_test_seq = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n",
    "y_train_seq = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test_seq = np_utils.to_categorical(y_test, nb_classes)\n",
    "print('X_train shape:', X_train_seq.shape)\n",
    "print('X_test shape:', X_test_seq.shape)\n",
    "print('y_train shape:', y_train_seq.shape)\n",
    "print('y_test shape:', y_test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b6b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(top_words, 128, dropout=0.2))\n",
    "model1.add(LSTM(128, dropout_W=0.2, dropout_U=0.2)) \n",
    "model1.add(Dense(nb_classes))\n",
    "model1.add(Activation('softmax'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdb1d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model1.fit(X_train_seq, y_train_seq, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1)\n",
    "score = model1.evaluate(X_test_seq, y_test_seq, batch_size=batch_size)\n",
    "print('Test loss : {:.4f}'.format(score[0]))\n",
    "print('Test accuracy : {:.4f}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ef617",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_seq),len(y_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf5806",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of weight matrix in the embedding layer : \", \\\n",
    "      model1.layers[0].get_weights()[0].shape)\n",
    "print(\"Size of weight matrix in the hidden layer : \", \\\n",
    "      model1.layers[1].get_weights()[0].shape)\n",
    "print(\"Size of weight matrix in the output layer : \", \\\n",
    "      model1.layers[2].get_weights()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860cf950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model1,open('model1.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a871ec39",
   "metadata": {},
   "source": [
    "# \n",
    "LSTM with Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52f73ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "2v = Word2Vec.load(\"w2v_300features_10minwordcounts_10context\")\n",
    "embedding_matrix = w2v.wv.syn0 \n",
    "print(\"Shape of embedding matrix : \", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a6033",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = embedding_matrix.shape[0] \n",
    "maxlen = 300 \n",
    "batch_size = 62\n",
    "nb_classes = 4\n",
    "nb_epoch = 7\n",
    "tokenizer = Tokenizer(nb_words=top_words) \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_seq1 = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n",
    "X_test_seq1 = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n",
    "y_train_seq1 = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test_seq1 = np_utils.to_categorical(y_test, nb_classes)\n",
    "print('X_train shape:', X_train_seq1.shape)\n",
    "print('X_test shape:', X_test_seq1.shape)\n",
    "print('y_train shape:', y_train_seq1.shape)\n",
    "print('y_test shape:', y_test_seq1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b5379",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_seq1),len(y_train_seq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee46d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1], \n",
    "                            weights=[embedding_matrix])\n",
    "model2 = Sequential()\n",
    "model2.add(embedding_layer)\n",
    "model2.add(LSTM(128, dropout_W=0.2, dropout_U=0.2)) \n",
    "model2.add(Dense(nb_classes))\n",
    "model2.add(Activation('softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(X_train_seq1, y_train_seq1, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1)\n",
    "score = model2.evaluate(X_test_seq1, y_test_seq1, batch_size=batch_size)\n",
    "print('Test loss : {:.4f}'.format(score[0]))\n",
    "print('Test accuracy : {:.4f}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of weight matrix in the embedding layer : \", \\\n",
    "      model2.layers[0].get_weights()[0].shape) \n",
    "print(\"Size of weight matrix in the hidden layer : \", \\\n",
    "      model2.layers[1].get_weights()[0].shape) \n",
    "print(\"Size of weight matrix in the output layer : \", \\\n",
    "      model2.layers[2].get_weights()[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
